{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLcobzyl_XSC"
   },
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Session 4 - Lab Exercise 7</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTrnzE2F_XSG"
   },
   "source": [
    "We will use the titanic dataset from Kaggle (https://www.kaggle.com/). This is a well-known dataset and we will use it for classification- if the passenger survived or passed away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j6ArYDQ_XSG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWRADHtI_XSI"
   },
   "outputs": [],
   "source": [
    "training_DF = pd.read_csv(r'C:\\Users\\prana\\OneDrive\\Desktop\\AI Sem 1\\Appl Maths concepts for ML\\Lab 2\\titanic_dataset_GBC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2vfeiv9_XSI"
   },
   "outputs": [],
   "source": [
    "training_DF['Age'].fillna(training_DF['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_w1em8c_XSI"
   },
   "outputs": [],
   "source": [
    "training_DF.drop('Cabin',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hfg6EEzx_XSJ"
   },
   "outputs": [],
   "source": [
    "training_DF.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-57Y2Pj_XSJ"
   },
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(training_DF['Sex'])\n",
    "embark = pd.get_dummies(training_DF['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQvIZubZ_XSK"
   },
   "outputs": [],
   "source": [
    "training_DF.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zKxEpBJ_XSK"
   },
   "outputs": [],
   "source": [
    "training_DF = pd.concat([training_DF,sex,embark],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsEBTZhz_XSL"
   },
   "outputs": [],
   "source": [
    "training_DF.drop(['female','C'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrwdRVN3_XSL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfoM36i7_XSL"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_DF.drop('Survived',axis=1),\n",
    "                                                    training_DF['Survived'], test_size=0.30,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wZ7xxJe_XSL"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f1PwJSk_XSM",
    "outputId": "ae142257-ecb7-452d-fa4c-9f438d8a5b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSGDClassifier(\\n    loss='hinge',\\n    penalty='l2',\\n    alpha=0.0001,\\n    l1_ratio=0.15,\\n    fit_intercept=True,\\n    max_iter=1000,\\n    tol=0.001,\\n    shuffle=True,\\n    verbose=0,\\n    epsilon=0.1,\\n    n_jobs=None,\\n    random_state=None,\\n    learning_rate='optimal',\\n    eta0=0.0,\\n    power_t=0.5,\\n    early_stopping=False,\\n    validation_fraction=0.1,\\n    n_iter_no_change=5,\\n    class_weight=None,\\n    warm_start=False,\\n    average=False,\\n)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore SGDClassifier parameters\n",
    "\n",
    "'''\n",
    "SGDClassifier(\n",
    "    loss='hinge',\n",
    "    penalty='l2',\n",
    "    alpha=0.0001,\n",
    "    l1_ratio=0.15,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.001,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    epsilon=0.1,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    learning_rate='optimal',\n",
    "    eta0=0.0,\n",
    "    power_t=0.5,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    class_weight=None,\n",
    "    warm_start=False,\n",
    "    average=False,\n",
    ")\n",
    "'''\n",
    "\n",
    "    # Let's form SGD models with variation in parameters loss and alpha\n",
    "    # loss: 'hinge', 'log', and 'modified_huber'\n",
    "    # alpha: 0.0001 and 0.001\n",
    "    # explain and dicuss your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz3B9Hem_XSM",
    "outputId": "c9ac60f6-11a3-48e5-9dfc-2aa2bed2057b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: log, Accuracy: 0.6067415730337079\n",
      "Loss value: hinge, Accuracy: 0.42696629213483145\n",
      "Loss value: modified_huber, Accuracy: 0.6329588014981273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_values = ['log', 'hinge', 'modified_huber']\n",
    "for loss_value in loss_values:\n",
    "    model = SGDClassifier(loss=loss_value, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f'Loss value: {loss_value}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e0kA9kF_XSM"
   },
   "source": [
    "## Conclusion\n",
    "Looking at the accuracy results, it seems like the 'modified_huber' loss works the best for our model, and the 'loss' function also performs quite well. However, the 'hinge' loss doesn't work as effectively and gives the lowest accuracy. This suggests that for our classification task, 'modified_huber' and 'loss' are better choices, while 'hinge' may not be the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDw3IpAC_XSN",
    "outputId": "9238392d-c575-4909-938e-1821cdf51ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha value: 0.0001, Accuracy: 0.42696629213483145\n",
      "Alpha value: 0.001, Accuracy: 0.6142322097378277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\prana\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.0001, 0.001]\n",
    "for alpha_value in alpha_values:\n",
    "    model = SGDClassifier(alpha=alpha_value, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f'Alpha value: {alpha_value}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMONBR8n_XSN"
   },
   "source": [
    "## Conclusion:\n",
    "\n",
    "Loss Values:\n",
    "\n",
    "Alpha = 0.0001: A lower alpha value (0.0001) results in a lower accuracy (0.4269). This suggests that with less regularization, the model may be overfitting to the training data, potentially capturing noise and exhibiting poorer generalization on unseen data.\n",
    "\n",
    "Alpha = 0.001: A higher alpha value (0.001) leads to a higher accuracy (0.6142). This indicates that increasing the regularization strength may be helping the model generalize better to unseen data by preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OrUQWT0_XSN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEKsw5ng_XSN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0qtCoxN_XSN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
